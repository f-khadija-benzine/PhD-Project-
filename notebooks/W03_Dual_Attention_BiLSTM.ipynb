{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  W03 â€” Dual Attention BiLSTM for RUL Prediction\n",
    "**Objective**: Train and evaluate the Dual-Attention BiLSTM model (Section III-C2) on M1.\n",
    "\n",
    "**Architecture**: Input â†’ Feature Attention â†’ BiLSTM â†’ Temporal Attention â†’ Dense â†’ RUL\n",
    "\n",
    "**Author**: Fatima Khadija Benzine  \n",
    "**Date**: 22 February 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "GPU available: False\n",
      "All modules imported âœ“\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "from data_loader import MultiDatasetLoader\n",
    "from preprocessing import PreprocessingPipelineBI, create_sliding_windows, evaluate_per_unit\n",
    "from attention import (\n",
    "    build_dual_attention_bilstm,\n",
    "    extract_attention_weights,\n",
    "    save_attention_weights,\n",
    ")\n",
    "\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"All modules imported âœ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FD001 dataset...\n",
      "  Files: train=True, test=True, rul=True\n",
      "  - Training data shape: (20631, 26)\n",
      "  - Training units: 100\n",
      "  - Training RUL range: [0, 361]\n",
      "  - Test data shape: (13096, 26)\n",
      "  - RUL values shape: (100, 1)\n",
      "  - Test units found: 100 (units: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]...)\n",
      "  - RUL values provided: 100\n",
      "    Unit 1: max_cycle=31, base_RUL=112\n",
      "    Unit 2: max_cycle=49, base_RUL=98\n",
      "    Unit 3: max_cycle=126, base_RUL=69\n",
      "âœ“ FD001 loaded: 20631 train, 13096 test samples\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "DATASET = 'FD001'\n",
    "W = 30  # window size\n",
    "FEATURE_SELECTION = 'correlation'  # <-- 'correlation', 'aficv', or 'sensor_only'\n",
    "\n",
    "# Load\n",
    "loader = MultiDatasetLoader()\n",
    "ds = loader.load_cmapss_dataset(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BI Fusion: FD001 (train) ===\n",
      "  Sensor data: (20631, 27)\n",
      "  BI data loaded: 20631 rows, 100 units\n",
      "  Fused data: (20631, 44)\n",
      "  Features: 21 sensor + 17 BI\n",
      "\n",
      "=== BI Fusion: FD001 (test) ===\n",
      "  Sensor data: (13096, 27)\n",
      "  BI data loaded: 20648 rows, 100 units\n",
      "  Fused data: (13096, 44)\n",
      "  Features: 21 sensor + 17 BI\n",
      "Fused shape: (20631, 44) train, (13096, 44) test\n"
     ]
    }
   ],
   "source": [
    "from bi_fusion import BIFusionPipeline, CONTINUOUS_BI_VARS\n",
    "from feature_selection import BIAwareFeatureSelector\n",
    "from feature_selection_aficv import AFICvFeatureSelector\n",
    "\n",
    "meta_cols = ['unit', 'cycle', 'rul']\n",
    "\n",
    "# --- Common preprocessing (Steps 0-3b) ---\n",
    "train_raw = ds['train'].copy()\n",
    "test_raw = ds['test'].copy()\n",
    "train_raw['rul'] = train_raw['rul'].clip(upper=125)\n",
    "if 'rul' in test_raw.columns:\n",
    "    test_raw['rul'] = test_raw['rul'].clip(upper=125)\n",
    "\n",
    "sensor_cols = [c for c in train_raw.columns if c.startswith('sensor_')]\n",
    "setting_cols = [c for c in train_raw.columns if c.startswith('setting_')]\n",
    "\n",
    "from preprocessing import DataNormalizer\n",
    "norm = DataNormalizer(method='minmax')\n",
    "train_norm = norm.fit_transform(train_raw, sensor_cols + setting_cols)\n",
    "test_norm = norm.transform(test_raw)\n",
    "\n",
    "fusion = BIFusionPipeline()\n",
    "train_fused = fusion.fuse(train_norm, DATASET, split='train', encode_categoricals=True)\n",
    "test_fused = fusion.fuse(test_norm, DATASET, split='test', encode_categoricals=True)\n",
    "bi_cols = fusion.get_bi_columns(train_fused)\n",
    "\n",
    "bi_cont = [c for c in CONTINUOUS_BI_VARS if c in train_fused.columns]\n",
    "bi_norm = DataNormalizer(method='minmax')\n",
    "train_fused = bi_norm.fit_transform(train_fused, bi_cont)\n",
    "test_fused = bi_norm.transform(test_fused)\n",
    "\n",
    "print(f\"Fused shape: {train_fused.shape} train, {test_fused.shape} test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Correlation-based feature selection ===\n",
      "\n",
      "=== BI-Aware Feature Selection ===\n",
      "  Input: 21 sensor + 17 BI + 3 setting = 41 total\n",
      "  Variance filter (sensor/settings only):\n",
      "    Removed 9: ['sensor_1', 'sensor_5', 'sensor_9', 'sensor_10', 'sensor_14', 'sensor_16', 'sensor_18', 'sensor_19', 'setting_3']\n",
      "    Kept 15 sensor/setting features\n",
      "    BI features: 17 (all exempt, all kept)\n",
      "  Correlation filter (tau=0.95):\n",
      "    Removed 0:\n",
      "  Final: 32 features (15 sensor/setting + 17 BI)\n",
      "\n",
      "Method: correlation\n",
      "Features (32): 15 sensor/setting + 17 BI\n",
      "Selected: ['sensor_2', 'sensor_3', 'sensor_4', 'sensor_6', 'sensor_7', 'sensor_8', 'sensor_11', 'sensor_12', 'sensor_13', 'sensor_15', 'sensor_17', 'sensor_20', 'sensor_21', 'setting_1', 'setting_2', 'pm_cost', 'cm_cost', 'labor_rate_standard', 'labor_rate_overtime', 'downtime_penalty', 'revenue_per_hour', 'spare_parts_available', 'spare_parts_lead_time', 'technician_available', 'maintenance_window', 'contract_penalty_active', 'production_priority_0', 'production_priority_1', 'production_priority_2', 'shift_pattern_0', 'shift_pattern_1', 'shift_pattern_2']\n"
     ]
    }
   ],
   "source": [
    "# --- Feature Selection ---\n",
    "if FEATURE_SELECTION == 'correlation':\n",
    "    print(\"=== Correlation-based feature selection ===\")\n",
    "    selector = BIAwareFeatureSelector(variance_threshold=0.01, correlation_threshold=0.95)\n",
    "    feature_names = selector.select_features(\n",
    "        data=train_fused, sensor_cols=sensor_cols,\n",
    "        bi_cols=bi_cols, setting_cols=setting_cols,\n",
    "        exclude_cols=meta_cols,\n",
    "    )\n",
    "    train_sel = selector.transform(train_fused, keep_cols=meta_cols)\n",
    "    test_sel = selector.transform(test_fused, keep_cols=meta_cols)\n",
    "\n",
    "elif FEATURE_SELECTION == 'aficv':\n",
    "    print(\"=== AFICv Stratified (90%) feature selection ===\")\n",
    "    selector = AFICvFeatureSelector(\n",
    "        base_learner='xgboost', n_folds=5, cumulative_threshold=0.90,\n",
    "    )\n",
    "    feature_names = selector.select_features_stratified(\n",
    "        data=train_fused, sensor_cols=sensor_cols,\n",
    "        bi_cols=bi_cols, setting_cols=setting_cols,\n",
    "        target_col='rul', group_col='unit',\n",
    "    )\n",
    "    train_sel = selector.transform(train_fused, keep_cols=meta_cols)\n",
    "    test_sel = selector.transform(test_fused, keep_cols=meta_cols)\n",
    "    \n",
    "elif FEATURE_SELECTION == 'sensor_only':\n",
    "    print(\"=== Sensor-only (no BI) â€” ablation baseline ===\")\n",
    "    selector = BIAwareFeatureSelector(variance_threshold=0.01, correlation_threshold=0.95)\n",
    "    # Run selection to get variance/correlation filtering on sensors\n",
    "    selector.select_features(\n",
    "        data=train_fused, sensor_cols=sensor_cols,\n",
    "        bi_cols=bi_cols, setting_cols=setting_cols,\n",
    "        exclude_cols=meta_cols,\n",
    "    )\n",
    "    # Keep only sensor/setting features, drop all BI\n",
    "    feature_names = [f for f in selector.selected_features \n",
    "                     if f.startswith('sensor_') or f.startswith('setting_')]\n",
    "    train_sel = train_fused[meta_cols + feature_names].copy()\n",
    "    test_sel = test_fused[meta_cols + feature_names].copy()\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unknown selection method: {FEATURE_SELECTION}\")\n",
    "\n",
    "n_features = len(feature_names)\n",
    "n_sensor = sum(1 for f in feature_names if f.startswith('sensor_') or f.startswith('setting_'))\n",
    "n_bi = n_features - n_sensor\n",
    "\n",
    "print(f\"\\nMethod: {FEATURE_SELECTION}\")\n",
    "print(f\"Features ({n_features}): {n_sensor} sensor/setting + {n_bi} BI\")\n",
    "print(f\"Selected: {feature_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sliding Window] W=30, features=32\n",
      "  Units: 100 total, 0 padded, 0 excluded\n",
      "  Output: X=(17731, 30, 32), y=(17731,)\n",
      "\n",
      "[Sliding Window] W=30, features=32\n",
      "  Units: 100 total, 0 padded, 0 excluded\n",
      "  Output: X=(10196, 30, 32), y=(10196,)\n",
      "\n",
      "X_train: (17731, 30, 32)  y_train: (17731,)\n",
      "X_test:  (10196, 30, 32)  y_test:  (10196,)\n"
     ]
    }
   ],
   "source": [
    "# Sliding windows\n",
    "PAD = False  # <-- SWITCH: True (all samples, zero-padded) or False (skip first W-1)\n",
    "\n",
    "X_train, y_train = create_sliding_windows(\n",
    "    train_sel, window_size=W, feature_cols=feature_names, target_col='rul', pad=PAD)\n",
    "X_test, y_test = create_sliding_windows(\n",
    "    test_sel, window_size=W, feature_cols=feature_names, target_col='rul', pad=PAD)\n",
    "\n",
    "print(f\"\\nX_train: {X_train.shape}  y_train: {y_train.shape}\")\n",
    "print(f\"X_test:  {X_test.shape}  y_test:  {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, attn_model = build_dual_attention_bilstm(\n",
    "    window_size=W,\n",
    "    n_features=n_features,\n",
    "    lstm_units=64,\n",
    "    feature_attention_dim=32,\n",
    "    temporal_attention_dim=64,\n",
    "    dropout_rate=0.3,\n",
    "    dense_units=32,\n",
    "    learning_rate=0.001,\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=10, restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6\n",
    "    ),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(history.history['loss'], label='Train')\n",
    "axes[0].plot(history.history['val_loss'], label='Validation')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('MSE Loss')\n",
    "axes[0].set_title('Loss', fontweight='bold')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(history.history['mae'], label='Train')\n",
    "axes[1].plot(history.history['val_mae'], label='Validation')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].set_title('Mean Absolute Error', fontweight='bold')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.suptitle('Dual-Attention BiLSTM Training â€” M1', fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=256).flatten()\n",
    "\n",
    "# Per-unit standard evaluation\n",
    "results = evaluate_per_unit(\n",
    "    y_true=y_test, y_pred=y_pred,\n",
    "    df=test_sel, window_size=W, pad=PAD,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter (per-unit last prediction)\n",
    "axes[0].scatter(results['true_last'], results['preds_last'], alpha=0.6, s=20)\n",
    "axes[0].plot([0, 125], [0, 125], 'r--', linewidth=1.5, label='Perfect')\n",
    "axes[0].set_xlabel('True RUL')\n",
    "axes[0].set_ylabel('Predicted RUL')\n",
    "axes[0].set_title(f\"Last-window (RMSE={results['rmse_last']:.2f}, Score={results['score_last']:.0f})\", fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].set_xlim(0, 130)\n",
    "axes[0].set_ylim(0, 130)\n",
    "\n",
    "# Error distribution\n",
    "errors = results['preds_last'] - results['true_last']\n",
    "axes[1].hist(errors, bins=20, alpha=0.7, edgecolor='black')\n",
    "axes[1].axvline(x=0, color='red', linestyle='--')\n",
    "axes[1].set_xlabel('Prediction Error (pred - true)')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Error Distribution (100 units)', fontweight='bold')\n",
    "\n",
    "plt.suptitle(f'Dual-Attention BiLSTM â€” M1 ({FEATURE_SELECTION}, pad={PAD})', fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Attention Weight Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract attention weights\n",
    "weights = extract_attention_weights(\n",
    "    attn_model, X_test, feature_names, batch_size=256\n",
    ")\n",
    "\n",
    "print(\"=== Global Feature Importance (Attention Weights) ===\")\n",
    "print(weights['feature_importance'].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance bar chart\n",
    "imp = weights['feature_importance']\n",
    "type_colors = {'sensor': '#1f77b4', 'setting': '#ff7f0e', 'BI': '#2ca02c'}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "data_plot = imp.iloc[::-1]\n",
    "colors = [type_colors[t] for t in data_plot['type']]\n",
    "\n",
    "ax.barh(range(len(data_plot)), data_plot['mean_attention_weight'],\n",
    "        color=colors, alpha=0.85)\n",
    "ax.set_yticks(range(len(data_plot)))\n",
    "ax.set_yticklabels(data_plot['feature'], fontsize=9)\n",
    "ax.set_xlabel('Mean Attention Weight')\n",
    "ax.set_title('Feature Attention â€” Learned Importance (M1)', fontweight='bold')\n",
    "\n",
    "legend_elements = [Patch(facecolor=c, label=t) for t, c in type_colors.items()]\n",
    "ax.legend(handles=legend_elements, loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal attention: average weights across test set\n",
    "mean_temporal = np.mean(weights['temporal_weights'], axis=0)  # (W,)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.bar(range(W), mean_temporal, color='#457b9d', alpha=0.8)\n",
    "ax.set_xlabel('Time Step in Window (0 = oldest, 29 = most recent)')\n",
    "ax.set_ylabel('Mean Attention Weight')\n",
    "ax.set_title('Temporal Attention â€” Which Time Steps Matter? (M1)', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Attention Dynamics: How Weights Change with Degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test samples by RUL range\n",
    "rul_bins = {\n",
    "    'Healthy (RUL > 100)': y_test > 100,\n",
    "    'Mid-life (40 < RUL â‰¤ 100)': (y_test > 40) & (y_test <= 100),\n",
    "    'Near failure (RUL â‰¤ 40)': y_test <= 40,\n",
    "}\n",
    "\n",
    "# Feature attention by degradation phase\n",
    "per_sample = weights['per_sample_importance']  # (n_samples, n_features)\n",
    "\n",
    "phase_importance = {}\n",
    "for phase, mask in rul_bins.items():\n",
    "    if mask.sum() > 0:\n",
    "        phase_importance[phase] = np.mean(per_sample[mask], axis=0)\n",
    "\n",
    "phase_df = pd.DataFrame(phase_importance, index=feature_names)\n",
    "\n",
    "# Heatmap\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "sns.heatmap(phase_df, annot=True, fmt='.3f', cmap='YlOrRd',\n",
    "            linewidths=0.5, ax=ax, cbar_kws={'label': 'Attention Weight'})\n",
    "ax.set_title('Feature Attention Across Degradation Phases (M1)', fontweight='bold')\n",
    "ax.set_ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey insight: do BI features get more/less attention near failure?\")\n",
    "for phase in phase_importance:\n",
    "    bi_weight = sum(phase_importance[phase][i] for i, f in enumerate(feature_names)\n",
    "                    if not f.startswith('sensor_') and not f.startswith('setting_'))\n",
    "    sensor_weight = sum(phase_importance[phase][i] for i, f in enumerate(feature_names)\n",
    "                        if f.startswith('sensor_') or f.startswith('setting_'))\n",
    "    print(f\"  {phase}: sensor={sensor_weight:.3f}, BI={bi_weight:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal attention by degradation phase\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "colors_phase = ['#66c2a5', '#fc8d62', '#e63946']\n",
    "for i, (phase, mask) in enumerate(rul_bins.items()):\n",
    "    if mask.sum() > 0:\n",
    "        mean_t = np.mean(weights['temporal_weights'][mask], axis=0)\n",
    "        ax.plot(range(W), mean_t, 'o-', label=phase, color=colors_phase[i],\n",
    "                markersize=4, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Time Step in Window')\n",
    "ax.set_ylabel('Mean Temporal Attention')\n",
    "ax.set_title('Temporal Attention by Degradation Phase (M1)', fontweight='bold')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Save Weights for Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save attention weights for later use by the recommendation module\n",
    "save_dir = project_root / 'results' / 'attention_weights'\n",
    "\n",
    "save_attention_weights(\n",
    "    weights_dict=weights,\n",
    "    save_dir=str(save_dir),\n",
    "    dataset_name=f'M1_{FEATURE_SELECTION}_pad{PAD}',\n",
    "    prefix='attn',\n",
    ")\n",
    "\n",
    "\n",
    "# Also save the trained model\n",
    "model_dir = project_root / 'results' / 'models'\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "model.save(model_dir / f'dual_attention_bilstm_M1_{FEATURE_SELECTION}_pad{PAD}.keras')\n",
    "print(f\"\\nModel saved to {model_dir}/dual_attention_bilstm_M1_{FEATURE_SELECTION}.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Summary\n",
    "\n",
    "| Metric | Value |\n",
    "|:---|:---|\n",
    "| RMSE | ... |\n",
    "| MAE | ... |\n",
    "| NASA Score | ... |\n",
    "\n",
    "### Saved for recommendation system:\n",
    "- `results/attention_weights/attn_M1_feature_importance.csv` â€” global feature ranking\n",
    "- `results/attention_weights/attn_M1_per_sample.npy` â€” per-sample weights for context-aware recommendations\n",
    "- `results/attention_weights/attn_M1_temporal.npy` â€” temporal weights\n",
    "- `results/attention_weights/attn_M1_predictions.csv` â€” RUL predictions\n",
    "\n",
    "### Next steps:\n",
    "- ML branch (XGBoost) + hybrid fusion\n",
    "- Repeat on M2â€“M4\n",
    "- SHAP comparison with attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ML Branch] random_forest â€” flatten\n",
      "  Input: (17731, 30, 32) â†’ Flattened: (17731, 960)\n",
      "  Training complete âœ“\n",
      "\n",
      "=== Per-Unit Evaluation (100/100 units) ===\n",
      "  Last window:  RMSE=15.46  MAE=11.56  Score=388.29\n",
      "  Mean window:  RMSE=42.92  Score=35143.31\n"
     ]
    }
   ],
   "source": [
    "from ml_branch import MLBranch, HybridPredictor\n",
    "\n",
    "# --- ML Branch ---\n",
    "ml = MLBranch(model_type='random_forest', flatten_strategy='flatten')  # <-- 'xgboost' or 'random_forest' | 'flatten' or 'statistics'\n",
    "ml.fit(X_train, y_train, feature_names=feature_names)\n",
    "\n",
    "y_pred_ml = ml.predict(X_test)\n",
    "\n",
    "\n",
    "# ML standalone evaluation\n",
    "results_ml = evaluate_per_unit(\n",
    "    y_true=y_test, y_pred=y_pred_ml,\n",
    "    df=test_sel, window_size=W, pad=PAD,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Hybrid fusion ---\n",
    "hybrid = HybridPredictor()\n",
    "hybrid.optimize_alpha(y_pred_dl, y_pred_ml, y_test, metric='rmse')\n",
    "y_pred_dl = model.predict(X_test, batch_size=256).flatten()\n",
    "y_pred_hybrid = hybrid.predict(y_pred_dl, y_pred_ml)\n",
    "results_hybrid = evaluate_per_unit(\n",
    "    y_true=y_test, y_pred=y_pred_hybrid,\n",
    "    df=test_sel, window_size=W, pad=PAD,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
