{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¬ W02 â€” Feature Selection: Correlation vs AFICv (M1â€“M4)\n",
    "**Objective**: Compare correlation-based and stratified AFICv feature selection across all 4 machine groups for the results section.\n",
    "\n",
    "**Author**: Fatima Khadija Benzine  \n",
    "**Date**: February 2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "from data_loader import MultiDatasetLoader\n",
    "from preprocessing import DataNormalizer\n",
    "from bi_fusion import BIFusionPipeline\n",
    "from feature_selection import BIAwareFeatureSelector\n",
    "from feature_selection_aficv import AFICvFeatureSelector\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"All modules imported âœ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Helper: Prepare Fused Data for Any Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = MultiDatasetLoader()\n",
    "\n",
    "def prepare_fused(dataset_name):\n",
    "    \"\"\"Load, normalize, and fuse with BI â€” no feature selection.\"\"\"\n",
    "    ds = loader.load_cmapss_dataset(dataset_name)\n",
    "    train = ds['train'].copy()\n",
    "    train['rul'] = train['rul'].clip(upper=125)\n",
    "    \n",
    "    sensor_cols = [c for c in train.columns if c.startswith('sensor_')]\n",
    "    setting_cols = [c for c in train.columns if c.startswith('setting_')]\n",
    "    \n",
    "    # Normalize sensors + settings\n",
    "    normalizer = DataNormalizer(method='minmax')\n",
    "    train = normalizer.fit_transform(train, sensor_cols + setting_cols)\n",
    "    \n",
    "    # Fuse with BI\n",
    "    fusion = BIFusionPipeline()\n",
    "    train = fusion.fuse(train, dataset_name, split='train', encode_categoricals=True)\n",
    "    \n",
    "    # Normalize continuous BI\n",
    "    from bi_fusion import CONTINUOUS_BI_VARS\n",
    "    bi_cont = [c for c in CONTINUOUS_BI_VARS if c in train.columns]\n",
    "    bi_norm = DataNormalizer(method='minmax')\n",
    "    train = bi_norm.fit_transform(train, bi_cont)\n",
    "    \n",
    "    bi_cols = fusion.get_bi_columns(train)\n",
    "    \n",
    "    return train, sensor_cols, setting_cols, bi_cols\n",
    "\n",
    "print(\"Helper ready âœ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Run Both Methods on M1â€“M4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['FD001', 'FD002', 'FD003', 'FD004']\n",
    "labels = {'FD001': 'M1', 'FD002': 'M2', 'FD003': 'M3', 'FD004': 'M4'}\n",
    "meta_cols = ['unit', 'cycle', 'rul']\n",
    "\n",
    "results = []\n",
    "\n",
    "for ds_name in datasets:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  {labels[ds_name]} ({ds_name})\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    train, sensor_cols, setting_cols, bi_cols = prepare_fused(ds_name)\n",
    "    all_features = sensor_cols + setting_cols + bi_cols\n",
    "    \n",
    "    # --- Method 1: Correlation-based ---\n",
    "    corr_sel = BIAwareFeatureSelector(variance_threshold=0.01, correlation_threshold=0.95)\n",
    "    corr_features = corr_sel.select_features(\n",
    "        data=train, sensor_cols=sensor_cols,\n",
    "        bi_cols=bi_cols, setting_cols=setting_cols,\n",
    "        exclude_cols=meta_cols,\n",
    "    )\n",
    "    \n",
    "    # --- Method 2: AFICv Stratified (90%) ---\n",
    "    aficv_sel = AFICvFeatureSelector(\n",
    "        base_learner='xgboost', n_folds=5, cumulative_threshold=0.90,\n",
    "    )\n",
    "    aficv_features = aficv_sel.select_features_stratified(\n",
    "        data=train, sensor_cols=sensor_cols,\n",
    "        bi_cols=bi_cols, setting_cols=setting_cols,\n",
    "        target_col='rul', group_col='unit',\n",
    "    )\n",
    "    \n",
    "    # Count types\n",
    "    def count(feats):\n",
    "        s = sum(1 for f in feats if f.startswith('sensor_') or f.startswith('setting_'))\n",
    "        return s, len(feats) - s\n",
    "    \n",
    "    corr_s, corr_b = count(corr_features)\n",
    "    aficv_s, aficv_b = count(aficv_features)\n",
    "    \n",
    "    results.append({\n",
    "        'Machine': labels[ds_name],\n",
    "        'corr_sensor': corr_s,\n",
    "        'corr_bi': corr_b,\n",
    "        'corr_total': len(corr_features),\n",
    "        'aficv_sensor': aficv_s,\n",
    "        'aficv_bi': aficv_b,\n",
    "        'aficv_total': len(aficv_features),\n",
    "        'corr_features': corr_features,\n",
    "        'aficv_features': aficv_features,\n",
    "    })\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Done âœ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Summary Table (for LaTeX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(results)\n",
    "\n",
    "display_df = summary[['Machine', \n",
    "                       'corr_sensor', 'corr_bi', 'corr_total',\n",
    "                       'aficv_sensor', 'aficv_bi', 'aficv_total']].copy()\n",
    "\n",
    "display_df.columns = ['Machine',\n",
    "                       'Corr: Sensor', 'Corr: BI', 'Corr: Total',\n",
    "                       'AFICv: Sensor', 'AFICv: BI', 'AFICv: Total']\n",
    "\n",
    "print(\"=== Feature Selection Comparison ===\")\n",
    "print(display_df.to_string(index=False))\n",
    "\n",
    "# LaTeX output\n",
    "print(\"\\n=== LaTeX Table ===\")\n",
    "print(display_df.to_latex(index=False, column_format='@{}lcccccc@{}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n",
    "\n",
    "machines = [r['Machine'] for r in results]\n",
    "x = np.arange(len(machines))\n",
    "width = 0.35\n",
    "\n",
    "# Left: Correlation-based\n",
    "axes[0].bar(x - width/2, [r['corr_sensor'] for r in results], width,\n",
    "            label='Sensor/Setting', color='#1f77b4')\n",
    "axes[0].bar(x + width/2, [r['corr_bi'] for r in results], width,\n",
    "            label='BI', color='#2ca02c')\n",
    "for i, r in enumerate(results):\n",
    "    axes[0].text(i, r['corr_total'] - max(r['corr_sensor'], r['corr_bi']) + 1,\n",
    "                 f\"={r['corr_total']}\", ha='center', fontweight='bold', fontsize=9)\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(machines)\n",
    "axes[0].set_ylabel('Number of Features')\n",
    "axes[0].set_title('Correlation-Based', fontweight='bold')\n",
    "axes[0].legend()\n",
    "\n",
    "# Right: AFICv Stratified 90%\n",
    "axes[1].bar(x - width/2, [r['aficv_sensor'] for r in results], width,\n",
    "            label='Sensor/Setting', color='#1f77b4')\n",
    "axes[1].bar(x + width/2, [r['aficv_bi'] for r in results], width,\n",
    "            label='BI', color='#2ca02c')\n",
    "for i, r in enumerate(results):\n",
    "    axes[1].text(i, max(r['aficv_sensor'], r['aficv_bi']) + 0.3,\n",
    "                 f\"={r['aficv_total']}\", ha='center', fontweight='bold', fontsize=9)\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(machines)\n",
    "axes[1].set_title('AFICv Stratified (90%)', fontweight='bold')\n",
    "axes[1].legend()\n",
    "\n",
    "fig.suptitle('Feature Selection Comparison Across Machine Groups',\n",
    "             fontsize=13, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Feature_Selection_Comparison_M1_M4.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Feature Overlap Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results:\n",
    "    corr_set = set(r['corr_features'])\n",
    "    aficv_set = set(r['aficv_features'])\n",
    "    common = corr_set & aficv_set\n",
    "    only_corr = corr_set - aficv_set\n",
    "    only_aficv = aficv_set - corr_set\n",
    "    \n",
    "    print(f\"\\n--- {r['Machine']} ---\")\n",
    "    print(f\"  Common ({len(common)}):     {sorted(common)}\")\n",
    "    print(f\"  Only Corr ({len(only_corr)}):  {sorted(only_corr)}\")\n",
    "    print(f\"  Only AFICv ({len(only_aficv)}): {sorted(only_aficv)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. AFICv: Top BI Features Across Datasets\n",
    "Which BI features are consistently selected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run to collect BI importance tables\n",
    "bi_rankings = {}\n",
    "\n",
    "for ds_name in datasets:\n",
    "    train, sensor_cols, setting_cols, bi_cols = prepare_fused(ds_name)\n",
    "    \n",
    "    sel = AFICvFeatureSelector(\n",
    "        base_learner='xgboost', n_folds=5, cumulative_threshold=0.90,\n",
    "    )\n",
    "    sel.select_features_stratified(\n",
    "        data=train, sensor_cols=sensor_cols,\n",
    "        bi_cols=bi_cols, setting_cols=setting_cols,\n",
    "        target_col='rul', group_col='unit',\n",
    "    )\n",
    "    \n",
    "    imp_bi = sel.get_importance_table(group='bi')\n",
    "    bi_rankings[labels[ds_name]] = imp_bi[['feature', 'normalized']].copy()\n",
    "\n",
    "# Combine into one table\n",
    "combined = bi_rankings['M1'].rename(columns={'normalized': 'M1'})\n",
    "for m in ['M2', 'M3', 'M4']:\n",
    "    combined = combined.merge(\n",
    "        bi_rankings[m].rename(columns={'normalized': m}),\n",
    "        on='feature', how='outer'\n",
    "    )\n",
    "\n",
    "combined['mean_rank'] = combined[['M1', 'M2', 'M3', 'M4']].mean(axis=1)\n",
    "combined = combined.sort_values('mean_rank', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"=== BI Feature Importance Across Datasets (normalized, within BI group) ===\")\n",
    "print(combined.to_string(index=False, float_format='%.3f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "plot_data = combined.set_index('feature')[['M1', 'M2', 'M3', 'M4']]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "sns.heatmap(plot_data, annot=True, fmt='.3f', cmap='YlOrRd',\n",
    "            linewidths=0.5, ax=ax, cbar_kws={'label': 'Normalized Importance'})\n",
    "ax.set_title('BI Feature Importance Across Machine Groups\\n(AFICv Stratified, within BI group)',\n",
    "             fontweight='bold')\n",
    "ax.set_ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.savefig('BI_Feature_Importance_Heatmap_M1_M4.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
