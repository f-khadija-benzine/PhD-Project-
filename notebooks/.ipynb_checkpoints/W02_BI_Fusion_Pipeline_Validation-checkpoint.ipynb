{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¬ W02 â€” BI Fusion Pipeline Validation\n",
    "**Objective**: Test the complete preprocessing pipeline with BI integration (Section III-B of the methodology).\n",
    "\n",
    "**Pipeline under test:**\n",
    "1. Load C-MAPSS sensor data â†’ `data_loader.py`\n",
    "2. Normalize sensor features (MinMax) â†’ `preprocessing.py`\n",
    "3. Fuse with BI data (forward-fill, one-hot encoding) â†’ `bi_fusion.py` (Section III-B3)\n",
    "4. BI-aware feature selection (variance + correlation) â†’ `feature_selection.py` (Section III-B4)\n",
    "\n",
    "**Author**: Fatima Khadija Benzine  \n",
    "**Date**: February 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Navigate up to project root so we can import from src/\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Expected src/: {project_root / 'src'}\")\n",
    "print(f\"Expected data/: {project_root / 'data'}\")\n",
    "\n",
    "# Verify files exist\n",
    "for f in ['src/data_loader.py', 'src/bi_fusion.py', 'src/feature_selection.py', 'src/preprocessing.py']:\n",
    "    p = project_root / f\n",
    "    status = 'âœ“' if p.exists() else 'âœ— MISSING'\n",
    "    print(f\"  {status}  {f}\")\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import MultiDatasetLoader\n",
    "from preprocessing import PreprocessingPipelineBI\n",
    "from bi_fusion import BIFusionPipeline, BIDataLoader, BI_DELTA_CONFIG\n",
    "from feature_selection import BIAwareFeatureSelector\n",
    "\n",
    "print(\"All modules imported successfully âœ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = MultiDatasetLoader()\n",
    "\n",
    "print(\"Loading FD001...\")\n",
    "fd001 = loader.load_fd001()\n",
    "train_raw = fd001['train']\n",
    "test_raw = fd001['test']\n",
    "\n",
    "print(f\"\\nTrain: {train_raw.shape}\")\n",
    "print(f\"Test:  {test_raw.shape}\")\n",
    "print(f\"Units: {train_raw['unit'].nunique()} train, {test_raw['unit'].nunique()} test\")\n",
    "print(f\"Columns: {list(train_raw.columns[:8])}...\")\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Inspect BI Data (before fusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_loader = BIDataLoader()\n",
    "bi_df = bi_loader.load_bi('FD001')\n",
    "\n",
    "print(f\"BI data shape: {bi_df.shape}\")\n",
    "print(f\"\\nColumns: {list(bi_df.columns)}\")\n",
    "print(f\"\\nUpdate frequencies (Delta_k):\")\n",
    "print(bi_loader.get_delta_summary().to_string(index=False))\n",
    "\n",
    "bi_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Delta behavior: BI variables stay constant within each Delta_k period\n",
    "unit1_bi = bi_df[bi_df['unit_id'] == 1].set_index('cycle')\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "# Delta=10: production_priority\n",
    "axes[0].step(unit1_bi.index, unit1_bi['production_priority'], where='post', linewidth=1.5)\n",
    "axes[0].set_ylabel('Production\\nPriority')\n",
    "axes[0].set_title('Î”_k = 10 cycles (MES â€” per shift)', fontsize=11, loc='left')\n",
    "axes[0].set_yticks([0, 1, 2])\n",
    "axes[0].set_yticklabels(['Low', 'Med', 'High'])\n",
    "\n",
    "# Delta=25: spare_parts_available\n",
    "axes[1].step(unit1_bi.index, unit1_bi['spare_parts_available'], where='post', \n",
    "             linewidth=1.5, color='tab:orange')\n",
    "axes[1].set_ylabel('Spare Parts\\nAvailable')\n",
    "axes[1].set_title('Î”_k = 25 cycles (ERP/Inventory â€” daily/weekly)', fontsize=11, loc='left')\n",
    "axes[1].set_yticks([0, 1])\n",
    "axes[1].set_yticklabels(['No', 'Yes'])\n",
    "\n",
    "# Delta=50: pm_cost\n",
    "axes[2].step(unit1_bi.index, unit1_bi['pm_cost'], where='post', \n",
    "             linewidth=1.5, color='tab:green')\n",
    "axes[2].set_ylabel('PM Cost ($)')\n",
    "axes[2].set_title('Î”_k = 50 cycles (ERP â€” monthly)', fontsize=11, loc='left')\n",
    "axes[2].set_xlabel('Cycle (= flight)')\n",
    "\n",
    "fig.suptitle('Multi-Rate BI Variables â€” Unit 1 (FD001)', fontsize=13, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Validate Degradation Correlation\n",
    "Per the mixed correlation design: `production_priority` and `downtime_penalty` should increase as the engine approaches failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add health index to BI data for analysis\n",
    "bi_with_hi = bi_df.copy()\n",
    "max_cycles = bi_with_hi.groupby('unit_id')['cycle'].transform('max')\n",
    "bi_with_hi['health_index'] = 1.0 - (bi_with_hi['cycle'] / max_cycles)\n",
    "bi_with_hi['life_phase'] = pd.cut(bi_with_hi['health_index'], \n",
    "                                   bins=[0, 0.3, 0.7, 1.0],\n",
    "                                   labels=['Near Failure', 'Mid Life', 'Healthy'])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# Production priority distribution by life phase\n",
    "phase_priority = bi_with_hi.groupby('life_phase')['production_priority'].value_counts(normalize=True)\n",
    "phase_priority = phase_priority.unstack(fill_value=0)\n",
    "phase_priority.columns = ['Low', 'Medium', 'High']\n",
    "phase_priority.loc[['Healthy', 'Mid Life', 'Near Failure']].plot(\n",
    "    kind='bar', stacked=True, ax=axes[0], color=['#66c2a5', '#fc8d62', '#e63946'])\n",
    "axes[0].set_title('Production Priority by Life Phase', fontweight='bold')\n",
    "axes[0].set_ylabel('Proportion')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "axes[0].legend(title='Priority')\n",
    "\n",
    "# Downtime penalty by life phase\n",
    "order = ['Healthy', 'Mid Life', 'Near Failure']\n",
    "bi_with_hi['life_phase'] = pd.Categorical(bi_with_hi['life_phase'], categories=order, ordered=True)\n",
    "sns.boxplot(data=bi_with_hi, x='life_phase', y='downtime_penalty', ax=axes[1],\n",
    "            order=order, palette=['#66c2a5', '#fc8d62', '#e63946'])\n",
    "axes[1].set_title('Downtime Penalty by Life Phase', fontweight='bold')\n",
    "axes[1].set_ylabel('Downtime Penalty ($/hr)')\n",
    "axes[1].set_xlabel('')\n",
    "\n",
    "fig.suptitle('Degradation-Correlated BI Variables â€” FD001', fontsize=13, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean production_priority by phase:\")\n",
    "print(bi_with_hi.groupby('life_phase')['production_priority'].mean())\n",
    "print(\"\\nMean downtime_penalty by phase:\")\n",
    "print(bi_with_hi.groupby('life_phase')['downtime_penalty'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Run Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = PreprocessingPipelineBI(\n",
    "    normalization_method='minmax',\n",
    "    variance_threshold=0.01,\n",
    "    correlation_threshold=0.95,\n",
    "    rul_max=125,\n",
    ")\n",
    "\n",
    "train_processed = pipeline.fit_transform(train_raw, 'FD001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to test data\n",
    "test_processed = pipeline.transform(test_raw, 'FD001')\n",
    "\n",
    "print(f\"Train processed: {train_processed.shape}\")\n",
    "print(f\"Test processed:  {test_processed.shape}\")\n",
    "train_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection report\n",
    "report = pipeline.get_selection_report()\n",
    "groups = pipeline.get_feature_groups()\n",
    "\n",
    "print(\"=== Feature Selection Report ===\")\n",
    "print(f\"Sensor/setting features selected: {len(groups['sensor']) + len(groups['setting'])}\")\n",
    "print(f\"  Sensors: {groups['sensor']}\")\n",
    "print(f\"  Settings: {groups['setting']}\")\n",
    "print(f\"\\nBI features selected: {len(groups['bi'])}\")\n",
    "print(f\"  {groups['bi']}\")\n",
    "print(f\"\\nRemoved (low variance): {report.get('variance_removed', [])}\")\n",
    "print(f\"Removed (high correlation): {report.get('correlation_removed', [])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Visualize Fused Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show one unit's fused features over its lifetime\n",
    "unit_id = 1\n",
    "unit_data = train_processed[train_processed['unit'] == unit_id].set_index('cycle')\n",
    "\n",
    "# Pick a few representative features from each group\n",
    "sensor_to_plot = [c for c in groups['sensor'] if c in unit_data.columns][:3]\n",
    "bi_to_plot = [c for c in groups['bi'] if c in unit_data.columns \n",
    "              and not any(c.startswith(p) for p in ['production_priority_', 'shift_pattern_'])][:3]\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 9), sharex=True)\n",
    "\n",
    "# Sensor features (normalized)\n",
    "for col in sensor_to_plot:\n",
    "    axes[0].plot(unit_data.index, unit_data[col], label=col, alpha=0.8)\n",
    "axes[0].set_ylabel('Normalized Value')\n",
    "axes[0].set_title('Sensor Features (normalized, change every cycle)', fontsize=11, loc='left')\n",
    "axes[0].legend(loc='upper left', fontsize=9)\n",
    "\n",
    "# BI features (original scale)\n",
    "for i, col in enumerate(bi_to_plot):\n",
    "    axes[1].step(unit_data.index, unit_data[col], where='post', \n",
    "                 label=col, alpha=0.8, linewidth=1.5)\n",
    "axes[1].set_ylabel('BI Value')\n",
    "axes[1].set_title('BI Features (multi-rate, step function)', fontsize=11, loc='left')\n",
    "axes[1].legend(loc='upper left', fontsize=9)\n",
    "\n",
    "# RUL\n",
    "axes[2].plot(unit_data.index, unit_data['rul'], color='red', linewidth=2)\n",
    "axes[2].axhline(y=125, color='gray', linestyle='--', alpha=0.5, label='RUL_max=125')\n",
    "axes[2].set_ylabel('RUL (cycles)')\n",
    "axes[2].set_xlabel('Cycle (= flight)')\n",
    "axes[2].set_title('Remaining Useful Life (clipped at 125)', fontsize=11, loc='left')\n",
    "axes[2].legend(loc='upper right', fontsize=9)\n",
    "\n",
    "fig.suptitle(f'Fused Sensor + BI Data â€” Unit {unit_id} (FD001)', \n",
    "             fontsize=13, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap: sensor vs BI features\n",
    "all_features = groups['sensor'] + groups['setting'] + groups['bi']\n",
    "# Keep only numeric columns that exist\n",
    "plot_cols = [c for c in all_features if c in train_processed.columns]\n",
    "\n",
    "corr = train_processed[plot_cols].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, mask=mask, cmap='RdBu_r', center=0, \n",
    "            vmin=-1, vmax=1, ax=ax, square=True,\n",
    "            linewidths=0.5, cbar_kws={'shrink': 0.6})\n",
    "ax.set_title('Feature Correlation Matrix (Sensor + BI)', fontweight='bold', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Cost Realism Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_full = bi_loader.load_bi('FD001')\n",
    "\n",
    "print(\"=== BI Data Statistics (FD001) ===\")\n",
    "cost_cols = ['pm_cost', 'cm_cost', 'downtime_penalty', 'revenue_per_hour']\n",
    "print(bi_full[cost_cols].describe().round(1))\n",
    "\n",
    "cm_pm_ratio = bi_full['cm_cost'].mean() / bi_full['pm_cost'].mean()\n",
    "print(f\"\\nCM/PM cost ratio: {cm_pm_ratio:.1f}x (industry standard: 5-10x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Multi-Dataset Validation (FD001-FD004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for ds_name in ['FD001', 'FD002', 'FD003', 'FD004']:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    try:\n",
    "        ds = loader.load_cmapss_dataset(ds_name)\n",
    "        p = PreprocessingPipelineBI(rul_max=125)\n",
    "        train_p = p.fit_transform(ds['train'], ds_name)\n",
    "        test_p = p.transform(ds['test'], ds_name)\n",
    "        g = p.get_feature_groups()\n",
    "        results[ds_name] = {\n",
    "            'train_shape': train_p.shape,\n",
    "            'test_shape': test_p.shape,\n",
    "            'n_sensor': len(g['sensor']),\n",
    "            'n_setting': len(g['setting']),\n",
    "            'n_bi': len(g['bi']),\n",
    "            'total_features': len(g['all']),\n",
    "            'status': 'âœ“',\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"  âœ— Failed: {e}\")\n",
    "        results[ds_name] = {'status': f'âœ— {e}'}\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"\\n=== Summary ===\")\n",
    "summary_df = pd.DataFrame(results).T\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Methodology Alignment Summary\n",
    "\n",
    "This section maps each pipeline step to the corresponding section in the thesis methodology.\n",
    "\n",
    "| Pipeline Step | Code Module | Methodology Section | Equation(s) | Status |\n",
    "|:---|:---|:---|:---|:---|\n",
    "| Data loading (C-MAPSS) | `data_loader.py` | III-B1 (Data Acquisition) | â€” | âœ“ |\n",
    "| RUL calculation & clipping | `preprocessing.py` | III-B2 (Piecewise Linear RUL) | Eq. 1-2 | âœ“ |\n",
    "| BI data temporal alignment | `bi_fusion.py` | III-B3 (BI Data Fusion) | Eq. 3-4 | âœ“ |\n",
    "| Source-driven Î”_k per variable | `bi_fusion.py` (`BI_DELTA_CONFIG`) | III-B3 (Update Frequencies) | â€” | âœ“ |\n",
    "| One-hot encoding of categoricals | `bi_fusion.py` (`_encode_categoricals`) | III-B3 (Eq. 5) | Eq. 5 | âœ“ |\n",
    "| Feature-level fusion (concat) | `bi_fusion.py` (`fuse`) | III-B3 (Eq. 6) | Eq. 6 | âœ“ |\n",
    "| Min-Max normalization | `preprocessing.py` (`DataNormalizer`) | III-B4 (Normalization) | Eq. 7-8 | âœ“ |\n",
    "| Variance-based filtering (sensor only) | `feature_selection.py` | III-B4 (Eq. 10) | Eq. 10 | âœ“ |\n",
    "| BI exemption from variance filter | `feature_selection.py` | III-B4 (BI-aware selection) | â€” | âœ“ |\n",
    "| Correlation-based filtering | `feature_selection.py` | III-B4 (Eq. 12) | Eq. 12 | âœ“ |\n",
    "| BI prioritization in corr. removal | `feature_selection.py` | III-B4 (BI retention) | â€” | âœ“ |\n",
    "\n",
    "### What remains for the next steps:\n",
    "\n",
    "| Next Step | Methodology Section | Status |\n",
    "|:---|:---|:---|\n",
    "| Sliding window generation | III-B5 (Sequence Construction) | â¬œ To do |\n",
    "| GA hyperparameter optimization | III-B4 (Eq. 14-15) | â¬œ To do |\n",
    "| Attention mechanism (BI-sensor weighting) | III-C2 (Eq. 16-18) | â¬œ To do |\n",
    "| Hybrid ML+DL model (XGBoost + CNN-LSTM) | III-C3-C4 (Eq. 19-32) | â¬œ To do |\n",
    "| SHAP explainability | III-D2 | â¬œ To do |\n",
    "| Cost-sensitive decision support | III-D3-D4 (Eq. 45-49) | â¬œ To do |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
