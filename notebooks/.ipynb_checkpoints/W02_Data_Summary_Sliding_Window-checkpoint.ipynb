{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š W02 â€” Data Summary: Sliding Window Shapes (Correlation vs AFICv)\n",
    "**Objective**: Generate a recap table of final data dimensions (samples, window, features) for both feature selection methods across M1â€“M4.\n",
    "\n",
    "**Author**: Fatima Khadija Benzine  \n",
    "**Date**: February 2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "from data_loader import MultiDatasetLoader\n",
    "from preprocessing import PreprocessingPipelineBI, DataNormalizer, create_sliding_windows\n",
    "from bi_fusion import BIFusionPipeline, CONTINUOUS_BI_VARS\n",
    "from feature_selection import BIAwareFeatureSelector\n",
    "from feature_selection_aficv import AFICvFeatureSelector\n",
    "\n",
    "print(\"All modules imported âœ“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = MultiDatasetLoader()\n",
    "datasets = ['FD001', 'FD002', 'FD003', 'FD004']\n",
    "labels = {'FD001': 'M1', 'FD002': 'M2', 'FD003': 'M3', 'FD004': 'M4'}\n",
    "meta_cols = ['unit', 'cycle', 'rul']\n",
    "W = 30\n",
    "\n",
    "results = []\n",
    "\n",
    "for ds_name in datasets:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  {labels[ds_name]} ({ds_name})\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    ds = loader.load_cmapss_dataset(ds_name)\n",
    "    train_raw = ds['train'].copy()\n",
    "    test_raw = ds['test'].copy()\n",
    "    \n",
    "    # --- Common preprocessing (Steps 0-3b) ---\n",
    "    train_raw['rul'] = train_raw['rul'].clip(upper=125)\n",
    "    if 'rul' in test_raw.columns:\n",
    "        test_raw['rul'] = test_raw['rul'].clip(upper=125)\n",
    "    \n",
    "    sensor_cols = [c for c in train_raw.columns if c.startswith('sensor_')]\n",
    "    setting_cols = [c for c in train_raw.columns if c.startswith('setting_')]\n",
    "    \n",
    "    # Normalize sensors\n",
    "    norm = DataNormalizer(method='minmax')\n",
    "    train_norm = norm.fit_transform(train_raw, sensor_cols + setting_cols)\n",
    "    test_norm = norm.transform(test_raw)\n",
    "    \n",
    "    # Fuse BI\n",
    "    fusion = BIFusionPipeline()\n",
    "    train_fused = fusion.fuse(train_norm, ds_name, split='train', encode_categoricals=True)\n",
    "    test_fused = fusion.fuse(test_norm, ds_name, split='test', encode_categoricals=True)\n",
    "    bi_cols = fusion.get_bi_columns(train_fused)\n",
    "    \n",
    "    # Normalize continuous BI\n",
    "    bi_cont = [c for c in CONTINUOUS_BI_VARS if c in train_fused.columns]\n",
    "    bi_norm = DataNormalizer(method='minmax')\n",
    "    train_fused = bi_norm.fit_transform(train_fused, bi_cont)\n",
    "    test_fused = bi_norm.transform(test_fused)\n",
    "    \n",
    "    # ============================================\n",
    "    # Method 1: Correlation-based\n",
    "    # ============================================\n",
    "    print(f\"\\n--- Correlation-based ---\")\n",
    "    corr_sel = BIAwareFeatureSelector(variance_threshold=0.01, correlation_threshold=0.95)\n",
    "    corr_features = corr_sel.select_features(\n",
    "        data=train_fused, sensor_cols=sensor_cols,\n",
    "        bi_cols=bi_cols, setting_cols=setting_cols,\n",
    "        exclude_cols=meta_cols,\n",
    "    )\n",
    "    \n",
    "    train_corr = corr_sel.transform(train_fused, keep_cols=meta_cols)\n",
    "    test_corr = corr_sel.transform(test_fused, keep_cols=meta_cols)\n",
    "    \n",
    "    X_train_corr, y_train_corr = create_sliding_windows(train_corr, window_size=W, target_col='rul')\n",
    "    X_test_corr, y_test_corr = create_sliding_windows(test_corr, window_size=W, target_col='rul')\n",
    "    \n",
    "    # ============================================\n",
    "    # Method 2: AFICv Stratified 90%\n",
    "    # ============================================\n",
    "    print(f\"\\n--- AFICv Stratified (90%) ---\")\n",
    "    aficv_sel = AFICvFeatureSelector(\n",
    "        base_learner='xgboost', n_folds=5, cumulative_threshold=0.90,\n",
    "    )\n",
    "    aficv_features = aficv_sel.select_features_stratified(\n",
    "        data=train_fused, sensor_cols=sensor_cols,\n",
    "        bi_cols=bi_cols, setting_cols=setting_cols,\n",
    "        target_col='rul', group_col='unit',\n",
    "    )\n",
    "    \n",
    "    train_aficv = aficv_sel.transform(train_fused, keep_cols=meta_cols)\n",
    "    test_aficv = aficv_sel.transform(test_fused, keep_cols=meta_cols)\n",
    "    \n",
    "    X_train_aficv, y_train_aficv = create_sliding_windows(train_aficv, window_size=W, target_col='rul')\n",
    "    X_test_aficv, y_test_aficv = create_sliding_windows(test_aficv, window_size=W, target_col='rul')\n",
    "    \n",
    "    # ============================================\n",
    "    # Collect results\n",
    "    # ============================================\n",
    "    n_corr_sensor = sum(1 for f in corr_features if f.startswith('sensor_') or f.startswith('setting_'))\n",
    "    n_corr_bi = len(corr_features) - n_corr_sensor\n",
    "    n_aficv_sensor = sum(1 for f in aficv_features if f.startswith('sensor_') or f.startswith('setting_'))\n",
    "    n_aficv_bi = len(aficv_features) - n_aficv_sensor\n",
    "    \n",
    "    results.append({\n",
    "        'Machine': labels[ds_name],\n",
    "        'Train units': train_raw['unit'].nunique(),\n",
    "        'Test units': test_raw['unit'].nunique(),\n",
    "        # Correlation\n",
    "        'Corr: features': len(corr_features),\n",
    "        'Corr: sensor': n_corr_sensor,\n",
    "        'Corr: BI': n_corr_bi,\n",
    "        'Corr: train samples': X_train_corr.shape[0],\n",
    "        'Corr: test samples': X_test_corr.shape[0],\n",
    "        'Corr: X_train shape': str(X_train_corr.shape),\n",
    "        'Corr: X_test shape': str(X_test_corr.shape),\n",
    "        # AFICv\n",
    "        'AFICv: features': len(aficv_features),\n",
    "        'AFICv: sensor': n_aficv_sensor,\n",
    "        'AFICv: BI': n_aficv_bi,\n",
    "        'AFICv: train samples': X_train_aficv.shape[0],\n",
    "        'AFICv: test samples': X_test_aficv.shape[0],\n",
    "        'AFICv: X_train shape': str(X_train_aficv.shape),\n",
    "        'AFICv: X_test shape': str(X_test_aficv.shape),\n",
    "    })\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Done âœ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Clean display table\n",
    "display_cols = [\n",
    "    'Machine', 'Train units', 'Test units',\n",
    "    'Corr: features', 'Corr: train samples', 'Corr: test samples',\n",
    "    'AFICv: features', 'AFICv: train samples', 'AFICv: test samples',\n",
    "]\n",
    "print(\"=== Data Dimensions Summary (W=30) ===\\n\")\n",
    "print(df[display_cols].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full shapes table\n",
    "shape_cols = [\n",
    "    'Machine',\n",
    "    'Corr: X_train shape', 'Corr: X_test shape',\n",
    "    'AFICv: X_train shape', 'AFICv: X_test shape',\n",
    "]\n",
    "print(\"=== Tensor Shapes (samples, W, features) ===\\n\")\n",
    "print(df[shape_cols].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LaTeX table for thesis\n",
    "print(\"=== LaTeX Table ===\")\n",
    "print()\n",
    "print(r\"\\begin{table}[htbp]\")\n",
    "print(r\"    \\centering\")\n",
    "print(r\"    \\caption{Data dimensions after preprocessing and sliding window ($W=30$).}\")\n",
    "print(r\"    \\label{tab:data_dimensions}\")\n",
    "print(r\"    \\resizebox{\\columnwidth}{!}{%\")\n",
    "print(r\"    \\begin{tabular}{@{}l cc cc cc cc@{}}\")\n",
    "print(r\"        \\toprule\")\n",
    "print(r\"        & & & \\multicolumn{3}{c}{\\textbf{Correlation-based}} & \\multicolumn{3}{c}{\\textbf{AFICv Stratified (90\\%)}} \\\\\")\n",
    "print(r\"        \\cmidrule(lr){4-6} \\cmidrule(lr){7-9}\")\n",
    "print(r\"        \\textbf{Machine} & \\textbf{Train} & \\textbf{Test} & Features & Train & Test & Features & Train & Test \\\\\")\n",
    "print(r\"        & units & units & & samples & samples & & samples & samples \\\\\")\n",
    "print(r\"        \\midrule\")\n",
    "for _, r in df.iterrows():\n",
    "    print(f\"        {r['Machine']} & {r['Train units']} & {r['Test units']} & \"\n",
    "          f\"{r['Corr: features']} & {r['Corr: train samples']} & {r['Corr: test samples']} & \"\n",
    "          f\"{r['AFICv: features']} & {r['AFICv: train samples']} & {r['AFICv: test samples']} \\\\\")\n",
    "print(r\"        \\bottomrule\")\n",
    "print(r\"    \\end{tabular}%\")\n",
    "print(r\"    }\")\n",
    "print(r\"\\end{table}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
