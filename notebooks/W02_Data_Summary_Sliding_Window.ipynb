{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š W02 â€” Data Summary: Sliding Window Shapes (Correlation vs AFICv)\n",
    "**Objective**: Generate a recap table of final data dimensions (samples, window, features) for both feature selection methods across M1â€“M4.\n",
    "\n",
    "**Author**: Fatima Khadija Benzine  \n",
    "**Date**: February 2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported âœ“\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "from data_loader import MultiDatasetLoader\n",
    "from preprocessing import PreprocessingPipelineBI, DataNormalizer, create_sliding_windows\n",
    "from bi_fusion import BIFusionPipeline, CONTINUOUS_BI_VARS\n",
    "from feature_selection import BIAwareFeatureSelector\n",
    "from feature_selection_aficv import AFICvFeatureSelector\n",
    "\n",
    "print(\"All modules imported âœ“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  M1 (FD001)\n",
      "======================================================================\n",
      "Loading FD001 dataset...\n",
      "  Files: train=True, test=True, rul=True\n",
      "  - Training data shape: (20631, 26)\n",
      "  - Training units: 100\n",
      "  - Training RUL range: [0, 361]\n",
      "  - Test data shape: (13096, 26)\n",
      "  - RUL values shape: (100, 1)\n",
      "  - Test units found: 100 (units: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]...)\n",
      "  - RUL values provided: 100\n",
      "    Unit 1: max_cycle=31, base_RUL=112\n",
      "    Unit 2: max_cycle=49, base_RUL=98\n",
      "    Unit 3: max_cycle=126, base_RUL=69\n",
      "âœ“ FD001 loaded: 20631 train, 13096 test samples\n",
      "\n",
      "=== BI Fusion: FD001 (train) ===\n",
      "  Sensor data: (20631, 27)\n",
      "  BI data loaded: 20631 rows, 100 units\n",
      "  Fused data: (20631, 44)\n",
      "  Features: 21 sensor + 17 BI\n",
      "\n",
      "=== BI Fusion: FD001 (test) ===\n",
      "  Sensor data: (13096, 27)\n",
      "  BI data loaded: 20648 rows, 100 units\n",
      "  Fused data: (13096, 44)\n",
      "  Features: 21 sensor + 17 BI\n",
      "\n",
      "--- Correlation-based ---\n",
      "\n",
      "=== BI-Aware Feature Selection ===\n",
      "  Input: 21 sensor + 17 BI + 3 setting = 41 total\n",
      "  Variance filter (sensor/settings only):\n",
      "    Removed 9: ['sensor_1', 'sensor_5', 'sensor_9', 'sensor_10', 'sensor_14', 'sensor_16', 'sensor_18', 'sensor_19', 'setting_3']\n",
      "    Kept 15 sensor/setting features\n",
      "    BI features: 17 (all exempt, all kept)\n",
      "  Correlation filter (tau=0.95):\n",
      "    Removed 0:\n",
      "  Final: 32 features (15 sensor/setting + 17 BI)\n",
      "\n",
      "[Sliding Window] W=30, features=32\n",
      "  Units: 100 total, 0 padded, 0 excluded\n",
      "  Output: X=(17731, 30, 32), y=(17731,)\n",
      "\n",
      "[Sliding Window] W=30, features=32\n",
      "  Units: 100 total, 0 padded, 0 excluded\n",
      "  Output: X=(10196, 30, 32), y=(10196,)\n",
      "\n",
      "--- AFICv Stratified (90%) ---\n",
      "\n",
      "============================================================\n",
      "AFICv Feature Selection (Stratified)\n",
      "============================================================\n",
      "  Learner: xgboost, K=5\n",
      "  Sensor/Setting: 24 candidates, threshold=90%\n",
      "  BI:             17 candidates, threshold=90%\n",
      "\n",
      "--- Sensor/Setting Group (24 features) ---\n",
      "  [Sensor] Fold 1/5: RÂ²=0.8358\n",
      "  [Sensor] Fold 2/5: RÂ²=0.7660\n",
      "  [Sensor] Fold 3/5: RÂ²=0.8136\n",
      "  [Sensor] Fold 4/5: RÂ²=0.7966\n",
      "  [Sensor] Fold 5/5: RÂ²=0.7785\n",
      "\n",
      "  Sensor selected: 8/24 (coverage=91.4%)\n",
      "  â†’ ['sensor_11', 'sensor_4', 'sensor_9', 'sensor_12', 'sensor_7', 'sensor_15', 'sensor_20', 'sensor_17']\n",
      "\n",
      "--- BI Group (17 features) ---\n",
      "  [BI] Fold 1/5: RÂ²=0.8716\n",
      "  [BI] Fold 2/5: RÂ²=0.8686\n",
      "  [BI] Fold 3/5: RÂ²=0.8753\n",
      "  [BI] Fold 4/5: RÂ²=0.8890\n",
      "  [BI] Fold 5/5: RÂ²=0.8722\n",
      "\n",
      "  BI selected: 8/17 (coverage=91.7%)\n",
      "  â†’ ['downtime_penalty', 'technician_available', 'cm_cost', 'revenue_per_hour', 'labor_rate_overtime', 'spare_parts_lead_time', 'labor_rate_standard', 'spare_parts_available']\n",
      "\n",
      "============================================================\n",
      "  TOTAL: 16 features (8 sensor/setting + 8 BI)\n",
      "============================================================\n",
      "\n",
      "[Sliding Window] W=30, features=16\n",
      "  Units: 100 total, 0 padded, 0 excluded\n",
      "  Output: X=(17731, 30, 16), y=(17731,)\n",
      "\n",
      "[Sliding Window] W=30, features=16\n",
      "  Units: 100 total, 0 padded, 0 excluded\n",
      "  Output: X=(10196, 30, 16), y=(10196,)\n",
      "\n",
      "======================================================================\n",
      "  M2 (FD002)\n",
      "======================================================================\n",
      "Loading FD002 dataset...\n",
      "  Files: train=True, test=True, rul=True\n",
      "  - Training data shape: (53759, 26)\n",
      "  - Training units: 260\n",
      "  - Training RUL range: [0, 377]\n",
      "  - Test data shape: (33991, 26)\n",
      "  - RUL values shape: (259, 1)\n",
      "  - Test units found: 259 (units: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]...)\n",
      "  - RUL values provided: 259\n",
      "    Unit 1: max_cycle=258, base_RUL=18\n",
      "    Unit 2: max_cycle=55, base_RUL=79\n",
      "    Unit 3: max_cycle=165, base_RUL=106\n",
      "âœ“ FD002 loaded: 53759 train, 33991 test samples\n",
      "\n",
      "=== BI Fusion: FD002 (train) ===\n",
      "  Sensor data: (53759, 28)\n",
      "  BI data loaded: 53759 rows, 260 units\n",
      "  Fused data: (53759, 45)\n",
      "  Features: 21 sensor + 17 BI\n",
      "\n",
      "=== BI Fusion: FD002 (test) ===\n",
      "  Sensor data: (33991, 28)\n",
      "  BI data loaded: 55018 rows, 259 units\n",
      "  Fused data: (33991, 45)\n",
      "  Features: 21 sensor + 17 BI\n",
      "\n",
      "--- Correlation-based ---\n",
      "\n",
      "=== BI-Aware Feature Selection ===\n",
      "  Input: 21 sensor + 17 BI + 3 setting = 41 total\n",
      "  Variance filter (sensor/settings only):\n",
      "    Removed 0: []\n",
      "    Kept 24 sensor/setting features\n",
      "    BI features: 17 (all exempt, all kept)\n",
      "  Correlation filter (tau=0.95):\n",
      "    Removed 17:\n",
      "      sensor_2: corr=0.982 with sensor_3, RUL corr: sensor_3=0.032 > sensor_2=0.007\n",
      "      sensor_3: corr=0.990 with sensor_4, RUL corr: sensor_4=0.048 > sensor_3=0.032\n",
      "      sensor_1: corr=0.986 with sensor_5, RUL corr: sensor_5=0.001 > sensor_1=0.001\n",
      "      sensor_5: corr=0.996 with sensor_6, RUL corr: sensor_6=0.001 > sensor_5=0.001\n",
      "      sensor_7: corr=0.957 with sensor_4, RUL corr: sensor_4=0.048 > sensor_7=0.002\n",
      "      sensor_9: corr=0.987 with sensor_4, RUL corr: sensor_4=0.048 > sensor_9=0.021\n",
      "      sensor_10: corr=0.962 with sensor_4, RUL corr: sensor_4=0.048 > sensor_10=0.003\n",
      "      sensor_8: corr=0.973 with sensor_11, RUL corr: sensor_11=0.055 > sensor_8=0.001\n",
      "      sensor_12: corr=0.957 with sensor_4, RUL corr: sensor_4=0.048 > sensor_12=0.002\n",
      "      sensor_15: corr=0.965 with sensor_11, RUL corr: sensor_11=0.055 > sensor_15=0.040\n",
      "      sensor_17: corr=0.990 with sensor_4, RUL corr: sensor_4=0.048 > sensor_17=0.033\n",
      "      sensor_18: corr=0.972 with sensor_11, RUL corr: sensor_11=0.055 > sensor_18=0.002\n",
      "      sensor_13: corr=1.000 with sensor_19, RUL corr: sensor_19=0.002 > sensor_13=0.002\n",
      "      sensor_6: corr=0.996 with sensor_20, RUL corr: sensor_20=0.007 > sensor_6=0.001\n",
      "      sensor_21: corr=1.000 with sensor_20, RUL corr: sensor_20=0.007 > sensor_21=0.006\n",
      "      setting_1: corr=0.962 with sensor_20, RUL corr: sensor_20=0.007 > setting_1=0.001\n",
      "      sensor_19: corr=1.000 with setting_3, RUL corr: setting_3=0.002 > sensor_19=0.002\n",
      "  Final: 24 features (7 sensor/setting + 17 BI)\n",
      "\n",
      "[Sliding Window] W=30, features=24\n",
      "  Units: 260 total, 0 padded, 0 excluded\n",
      "  Output: X=(46219, 30, 24), y=(46219,)\n",
      "\n",
      "[Sliding Window] W=30, features=24\n",
      "  Units: 259 total, 6 padded, 0 excluded\n",
      "  Output: X=(26511, 30, 24), y=(26511,)\n",
      "\n",
      "--- AFICv Stratified (90%) ---\n",
      "\n",
      "============================================================\n",
      "AFICv Feature Selection (Stratified)\n",
      "============================================================\n",
      "  Learner: xgboost, K=5\n",
      "  Sensor/Setting: 24 candidates, threshold=90%\n",
      "  BI:             17 candidates, threshold=90%\n",
      "\n",
      "--- Sensor/Setting Group (24 features) ---\n",
      "  [Sensor] Fold 1/5: RÂ²=0.7689\n",
      "  [Sensor] Fold 2/5: RÂ²=0.7333\n",
      "  [Sensor] Fold 3/5: RÂ²=0.7755\n",
      "  [Sensor] Fold 4/5: RÂ²=0.7854\n",
      "  [Sensor] Fold 5/5: RÂ²=0.7758\n",
      "\n",
      "  Sensor selected: 11/24 (coverage=91.6%)\n",
      "  â†’ ['sensor_13', 'sensor_15', 'sensor_11', 'sensor_4', 'sensor_1', 'sensor_14', 'sensor_16', 'sensor_17', 'sensor_2', 'sensor_9', 'sensor_6']\n",
      "\n",
      "--- BI Group (17 features) ---\n",
      "  [BI] Fold 1/5: RÂ²=0.8703\n",
      "  [BI] Fold 2/5: RÂ²=0.8668\n",
      "  [BI] Fold 3/5: RÂ²=0.8845\n",
      "  [BI] Fold 4/5: RÂ²=0.8960\n",
      "  [BI] Fold 5/5: RÂ²=0.8474\n",
      "\n",
      "  BI selected: 6/17 (coverage=90.7%)\n",
      "  â†’ ['downtime_penalty', 'technician_available', 'production_priority_2', 'cm_cost', 'labor_rate_standard', 'pm_cost']\n",
      "\n",
      "============================================================\n",
      "  TOTAL: 17 features (11 sensor/setting + 6 BI)\n",
      "============================================================\n",
      "\n",
      "[Sliding Window] W=30, features=17\n",
      "  Units: 260 total, 0 padded, 0 excluded\n",
      "  Output: X=(46219, 30, 17), y=(46219,)\n",
      "\n",
      "[Sliding Window] W=30, features=17\n",
      "  Units: 259 total, 6 padded, 0 excluded\n",
      "  Output: X=(26511, 30, 17), y=(26511,)\n",
      "\n",
      "======================================================================\n",
      "  M3 (FD003)\n",
      "======================================================================\n",
      "Loading FD003 dataset...\n",
      "  Files: train=True, test=True, rul=True\n",
      "  - Training data shape: (24720, 26)\n",
      "  - Training units: 100\n",
      "  - Training RUL range: [0, 524]\n",
      "  - Test data shape: (16596, 26)\n",
      "  - RUL values shape: (100, 1)\n",
      "  - Test units found: 100 (units: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]...)\n",
      "  - RUL values provided: 100\n",
      "    Unit 1: max_cycle=233, base_RUL=44\n",
      "    Unit 2: max_cycle=124, base_RUL=51\n",
      "    Unit 3: max_cycle=234, base_RUL=27\n",
      "âœ“ FD003 loaded: 24720 train, 16596 test samples\n",
      "\n",
      "=== BI Fusion: FD003 (train) ===\n",
      "  Sensor data: (24720, 27)\n",
      "  BI data loaded: 24720 rows, 100 units\n",
      "  Fused data: (24720, 44)\n",
      "  Features: 21 sensor + 17 BI\n",
      "\n",
      "=== BI Fusion: FD003 (test) ===\n",
      "  Sensor data: (16596, 27)\n",
      "  BI data loaded: 24128 rows, 100 units\n",
      "  Fused data: (16596, 44)\n",
      "  Features: 21 sensor + 17 BI\n",
      "\n",
      "--- Correlation-based ---\n",
      "\n",
      "=== BI-Aware Feature Selection ===\n",
      "  Input: 21 sensor + 17 BI + 3 setting = 41 total\n",
      "  Variance filter (sensor/settings only):\n",
      "    Removed 10: ['sensor_1', 'sensor_5', 'sensor_8', 'sensor_9', 'sensor_13', 'sensor_14', 'sensor_16', 'sensor_18', 'sensor_19', 'setting_3']\n",
      "    Kept 14 sensor/setting features\n",
      "    BI features: 17 (all exempt, all kept)\n",
      "  Correlation filter (tau=0.95):\n",
      "    Removed 1:\n",
      "      sensor_7: corr=0.989 with sensor_12, RUL corr: sensor_12=0.375 > sensor_7=0.357\n",
      "  Final: 30 features (13 sensor/setting + 17 BI)\n",
      "\n",
      "[Sliding Window] W=30, features=30\n",
      "  Units: 100 total, 0 padded, 0 excluded\n",
      "  Output: X=(21820, 30, 30), y=(21820,)\n",
      "\n",
      "[Sliding Window] W=30, features=30\n",
      "  Units: 100 total, 0 padded, 0 excluded\n",
      "  Output: X=(13696, 30, 30), y=(13696,)\n",
      "\n",
      "--- AFICv Stratified (90%) ---\n",
      "\n",
      "============================================================\n",
      "AFICv Feature Selection (Stratified)\n",
      "============================================================\n",
      "  Learner: xgboost, K=5\n",
      "  Sensor/Setting: 24 candidates, threshold=90%\n",
      "  BI:             17 candidates, threshold=90%\n",
      "\n",
      "--- Sensor/Setting Group (24 features) ---\n",
      "  [Sensor] Fold 1/5: RÂ²=0.8512\n",
      "  [Sensor] Fold 2/5: RÂ²=0.8245\n",
      "  [Sensor] Fold 3/5: RÂ²=0.7711\n",
      "  [Sensor] Fold 4/5: RÂ²=0.8299\n",
      "  [Sensor] Fold 5/5: RÂ²=0.8591\n",
      "\n",
      "  Sensor selected: 7/24 (coverage=91.4%)\n",
      "  â†’ ['sensor_11', 'sensor_9', 'sensor_17', 'sensor_13', 'sensor_8', 'sensor_4', 'sensor_14']\n",
      "\n",
      "--- BI Group (17 features) ---\n",
      "  [BI] Fold 1/5: RÂ²=0.7675\n",
      "  [BI] Fold 2/5: RÂ²=0.7347\n",
      "  [BI] Fold 3/5: RÂ²=0.7495\n",
      "  [BI] Fold 4/5: RÂ²=0.7374\n",
      "  [BI] Fold 5/5: RÂ²=0.8051\n",
      "\n",
      "  BI selected: 8/17 (coverage=91.0%)\n",
      "  â†’ ['downtime_penalty', 'labor_rate_overtime', 'pm_cost', 'labor_rate_standard', 'cm_cost', 'technician_available', 'spare_parts_available', 'revenue_per_hour']\n",
      "\n",
      "============================================================\n",
      "  TOTAL: 15 features (7 sensor/setting + 8 BI)\n",
      "============================================================\n",
      "\n",
      "[Sliding Window] W=30, features=15\n",
      "  Units: 100 total, 0 padded, 0 excluded\n",
      "  Output: X=(21820, 30, 15), y=(21820,)\n",
      "\n",
      "[Sliding Window] W=30, features=15\n",
      "  Units: 100 total, 0 padded, 0 excluded\n",
      "  Output: X=(13696, 30, 15), y=(13696,)\n",
      "\n",
      "======================================================================\n",
      "  M4 (FD004)\n",
      "======================================================================\n",
      "Loading FD004 dataset...\n",
      "  Files: train=True, test=True, rul=True\n",
      "  - Training data shape: (61249, 26)\n",
      "  - Training units: 249\n",
      "  - Training RUL range: [0, 542]\n",
      "  - Test data shape: (41214, 26)\n",
      "  - RUL values shape: (248, 1)\n",
      "  - Test units found: 248 (units: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]...)\n",
      "  - RUL values provided: 248\n",
      "    Unit 1: max_cycle=230, base_RUL=22\n",
      "    Unit 2: max_cycle=153, base_RUL=39\n",
      "    Unit 3: max_cycle=141, base_RUL=107\n",
      "âœ“ FD004 loaded: 61249 train, 41214 test samples\n",
      "\n",
      "=== BI Fusion: FD004 (train) ===\n",
      "  Sensor data: (61249, 28)\n",
      "  BI data loaded: 61249 rows, 249 units\n",
      "  Fused data: (61249, 45)\n",
      "  Features: 21 sensor + 17 BI\n",
      "\n",
      "=== BI Fusion: FD004 (test) ===\n",
      "  Sensor data: (41214, 28)\n",
      "  BI data loaded: 62679 rows, 248 units\n",
      "  Fused data: (41214, 45)\n",
      "  Features: 21 sensor + 17 BI\n",
      "\n",
      "--- Correlation-based ---\n",
      "\n",
      "=== BI-Aware Feature Selection ===\n",
      "  Input: 21 sensor + 17 BI + 3 setting = 41 total\n",
      "  Variance filter (sensor/settings only):\n",
      "    Removed 0: []\n",
      "    Kept 24 sensor/setting features\n",
      "    BI features: 17 (all exempt, all kept)\n",
      "  Correlation filter (tau=0.95):\n",
      "    Removed 17:\n",
      "      sensor_2: corr=0.982 with sensor_3, RUL corr: sensor_3=0.041 > sensor_2=0.009\n",
      "      sensor_3: corr=0.990 with sensor_4, RUL corr: sensor_4=0.056 > sensor_3=0.041\n",
      "      sensor_5: corr=0.987 with sensor_1, RUL corr: sensor_1=0.000 > sensor_5=0.000\n",
      "      sensor_1: corr=0.987 with sensor_6, RUL corr: sensor_6=0.001 > sensor_1=0.000\n",
      "      sensor_7: corr=0.956 with sensor_4, RUL corr: sensor_4=0.056 > sensor_7=0.005\n",
      "      sensor_9: corr=0.988 with sensor_4, RUL corr: sensor_4=0.056 > sensor_9=0.035\n",
      "      sensor_10: corr=0.961 with sensor_4, RUL corr: sensor_4=0.056 > sensor_10=0.016\n",
      "      sensor_8: corr=0.972 with sensor_11, RUL corr: sensor_11=0.068 > sensor_8=0.003\n",
      "      sensor_12: corr=0.957 with sensor_4, RUL corr: sensor_4=0.056 > sensor_12=0.005\n",
      "      sensor_15: corr=0.964 with sensor_11, RUL corr: sensor_11=0.068 > sensor_15=0.005\n",
      "      sensor_17: corr=0.990 with sensor_4, RUL corr: sensor_4=0.056 > sensor_17=0.041\n",
      "      sensor_18: corr=0.972 with sensor_11, RUL corr: sensor_11=0.068 > sensor_18=0.003\n",
      "      sensor_19: corr=1.000 with sensor_13, RUL corr: sensor_13=0.004 > sensor_19=0.003\n",
      "      sensor_20: corr=0.996 with sensor_6, RUL corr: sensor_6=0.001 > sensor_20=0.000\n",
      "      sensor_21: corr=0.996 with sensor_6, RUL corr: sensor_6=0.001 > sensor_21=0.000\n",
      "      setting_1: corr=0.977 with sensor_6, RUL corr: sensor_6=0.001 > setting_1=0.000\n",
      "      setting_3: corr=1.000 with sensor_13, RUL corr: sensor_13=0.004 > setting_3=0.003\n",
      "  Final: 24 features (7 sensor/setting + 17 BI)\n",
      "\n",
      "[Sliding Window] W=30, features=24\n",
      "  Units: 249 total, 0 padded, 0 excluded\n",
      "  Output: X=(54028, 30, 24), y=(54028,)\n",
      "\n",
      "[Sliding Window] W=30, features=24\n",
      "  Units: 248 total, 11 padded, 0 excluded\n",
      "  Output: X=(34092, 30, 24), y=(34092,)\n",
      "\n",
      "--- AFICv Stratified (90%) ---\n",
      "\n",
      "============================================================\n",
      "AFICv Feature Selection (Stratified)\n",
      "============================================================\n",
      "  Learner: xgboost, K=5\n",
      "  Sensor/Setting: 24 candidates, threshold=90%\n",
      "  BI:             17 candidates, threshold=90%\n",
      "\n",
      "--- Sensor/Setting Group (24 features) ---\n",
      "  [Sensor] Fold 1/5: RÂ²=0.7574\n",
      "  [Sensor] Fold 2/5: RÂ²=0.7985\n",
      "  [Sensor] Fold 3/5: RÂ²=0.7993\n",
      "  [Sensor] Fold 4/5: RÂ²=0.8059\n",
      "  [Sensor] Fold 5/5: RÂ²=0.8354\n",
      "\n",
      "  Sensor selected: 10/24 (coverage=90.0%)\n",
      "  â†’ ['sensor_13', 'sensor_11', 'sensor_15', 'sensor_4', 'sensor_14', 'sensor_10', 'sensor_9', 'sensor_12', 'sensor_8', 'sensor_7']\n",
      "\n",
      "--- BI Group (17 features) ---\n",
      "  [BI] Fold 1/5: RÂ²=0.8254\n",
      "  [BI] Fold 2/5: RÂ²=0.8293\n",
      "  [BI] Fold 3/5: RÂ²=0.8360\n",
      "  [BI] Fold 4/5: RÂ²=0.8485\n",
      "  [BI] Fold 5/5: RÂ²=0.8308\n",
      "\n",
      "  BI selected: 7/17 (coverage=90.7%)\n",
      "  â†’ ['downtime_penalty', 'cm_cost', 'labor_rate_standard', 'labor_rate_overtime', 'revenue_per_hour', 'pm_cost', 'spare_parts_available']\n",
      "\n",
      "============================================================\n",
      "  TOTAL: 17 features (10 sensor/setting + 7 BI)\n",
      "============================================================\n",
      "\n",
      "[Sliding Window] W=30, features=17\n",
      "  Units: 249 total, 0 padded, 0 excluded\n",
      "  Output: X=(54028, 30, 17), y=(54028,)\n",
      "\n",
      "[Sliding Window] W=30, features=17\n",
      "  Units: 248 total, 11 padded, 0 excluded\n",
      "  Output: X=(34092, 30, 17), y=(34092,)\n",
      "\n",
      "======================================================================\n",
      "Done âœ“\n"
     ]
    }
   ],
   "source": [
    "loader = MultiDatasetLoader()\n",
    "datasets = ['FD001', 'FD002', 'FD003', 'FD004']\n",
    "labels = {'FD001': 'M1', 'FD002': 'M2', 'FD003': 'M3', 'FD004': 'M4'}\n",
    "meta_cols = ['unit', 'cycle', 'rul']\n",
    "W = 30\n",
    "\n",
    "results = []\n",
    "\n",
    "for ds_name in datasets:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  {labels[ds_name]} ({ds_name})\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    ds = loader.load_cmapss_dataset(ds_name)\n",
    "    train_raw = ds['train'].copy()\n",
    "    test_raw = ds['test'].copy()\n",
    "    \n",
    "    # --- Common preprocessing (Steps 0-3b) ---\n",
    "    train_raw['rul'] = train_raw['rul'].clip(upper=125)\n",
    "    if 'rul' in test_raw.columns:\n",
    "        test_raw['rul'] = test_raw['rul'].clip(upper=125)\n",
    "    \n",
    "    sensor_cols = [c for c in train_raw.columns if c.startswith('sensor_')]\n",
    "    setting_cols = [c for c in train_raw.columns if c.startswith('setting_')]\n",
    "    \n",
    "    # Normalize sensors\n",
    "    norm = DataNormalizer(method='minmax')\n",
    "    train_norm = norm.fit_transform(train_raw, sensor_cols + setting_cols)\n",
    "    test_norm = norm.transform(test_raw)\n",
    "    \n",
    "    # Fuse BI\n",
    "    fusion = BIFusionPipeline()\n",
    "    train_fused = fusion.fuse(train_norm, ds_name, split='train', encode_categoricals=True)\n",
    "    test_fused = fusion.fuse(test_norm, ds_name, split='test', encode_categoricals=True)\n",
    "    bi_cols = fusion.get_bi_columns(train_fused)\n",
    "    \n",
    "    # Normalize continuous BI\n",
    "    bi_cont = [c for c in CONTINUOUS_BI_VARS if c in train_fused.columns]\n",
    "    bi_norm = DataNormalizer(method='minmax')\n",
    "    train_fused = bi_norm.fit_transform(train_fused, bi_cont)\n",
    "    test_fused = bi_norm.transform(test_fused)\n",
    "    \n",
    "    # ============================================\n",
    "    # Method 1: Correlation-based\n",
    "    # ============================================\n",
    "    print(f\"\\n--- Correlation-based ---\")\n",
    "    corr_sel = BIAwareFeatureSelector(variance_threshold=0.01, correlation_threshold=0.95)\n",
    "    corr_features = corr_sel.select_features(\n",
    "        data=train_fused, sensor_cols=sensor_cols,\n",
    "        bi_cols=bi_cols, setting_cols=setting_cols,\n",
    "        exclude_cols=meta_cols,\n",
    "    )\n",
    "    \n",
    "    train_corr = corr_sel.transform(train_fused, keep_cols=meta_cols)\n",
    "    test_corr = corr_sel.transform(test_fused, keep_cols=meta_cols)\n",
    "    \n",
    "    X_train_corr, y_train_corr = create_sliding_windows(train_corr, window_size=W, target_col='rul')\n",
    "    X_test_corr, y_test_corr = create_sliding_windows(test_corr, window_size=W, target_col='rul')\n",
    "    \n",
    "    # ============================================\n",
    "    # Method 2: AFICv Stratified 90%\n",
    "    # ============================================\n",
    "    print(f\"\\n--- AFICv Stratified (90%) ---\")\n",
    "    aficv_sel = AFICvFeatureSelector(\n",
    "        base_learner='xgboost', n_folds=5, cumulative_threshold=0.90,\n",
    "    )\n",
    "    aficv_features = aficv_sel.select_features_stratified(\n",
    "        data=train_fused, sensor_cols=sensor_cols,\n",
    "        bi_cols=bi_cols, setting_cols=setting_cols,\n",
    "        target_col='rul', group_col='unit',\n",
    "    )\n",
    "    \n",
    "    train_aficv = aficv_sel.transform(train_fused, keep_cols=meta_cols)\n",
    "    test_aficv = aficv_sel.transform(test_fused, keep_cols=meta_cols)\n",
    "    \n",
    "    X_train_aficv, y_train_aficv = create_sliding_windows(train_aficv, window_size=W, target_col='rul')\n",
    "    X_test_aficv, y_test_aficv = create_sliding_windows(test_aficv, window_size=W, target_col='rul')\n",
    "    \n",
    "    # ============================================\n",
    "    # Collect results\n",
    "    # ============================================\n",
    "    n_corr_sensor = sum(1 for f in corr_features if f.startswith('sensor_') or f.startswith('setting_'))\n",
    "    n_corr_bi = len(corr_features) - n_corr_sensor\n",
    "    n_aficv_sensor = sum(1 for f in aficv_features if f.startswith('sensor_') or f.startswith('setting_'))\n",
    "    n_aficv_bi = len(aficv_features) - n_aficv_sensor\n",
    "    \n",
    "    results.append({\n",
    "        'Machine': labels[ds_name],\n",
    "        'Train units': train_raw['unit'].nunique(),\n",
    "        'Test units': test_raw['unit'].nunique(),\n",
    "        # Correlation\n",
    "        'Corr: features': len(corr_features),\n",
    "        'Corr: sensor': n_corr_sensor,\n",
    "        'Corr: BI': n_corr_bi,\n",
    "        'Corr: train samples': X_train_corr.shape[0],\n",
    "        'Corr: test samples': X_test_corr.shape[0],\n",
    "        'Corr: X_train shape': str(X_train_corr.shape),\n",
    "        'Corr: X_test shape': str(X_test_corr.shape),\n",
    "        # AFICv\n",
    "        'AFICv: features': len(aficv_features),\n",
    "        'AFICv: sensor': n_aficv_sensor,\n",
    "        'AFICv: BI': n_aficv_bi,\n",
    "        'AFICv: train samples': X_train_aficv.shape[0],\n",
    "        'AFICv: test samples': X_test_aficv.shape[0],\n",
    "        'AFICv: X_train shape': str(X_train_aficv.shape),\n",
    "        'AFICv: X_test shape': str(X_test_aficv.shape),\n",
    "    })\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Done âœ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Dimensions Summary (W=30) ===\n",
      "\n",
      "Machine  Train units  Test units  Corr: features  Corr: train samples  Corr: test samples  AFICv: features  AFICv: train samples  AFICv: test samples\n",
      "     M1          100         100              32                17731               10196               16                 17731                10196\n",
      "     M2          260         259              24                46219               26511               17                 46219                26511\n",
      "     M3          100         100              30                21820               13696               15                 21820                13696\n",
      "     M4          249         248              24                54028               34092               17                 54028                34092\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Clean display table\n",
    "display_cols = [\n",
    "    'Machine', 'Train units', 'Test units',\n",
    "    'Corr: features', 'Corr: train samples', 'Corr: test samples',\n",
    "    'AFICv: features', 'AFICv: train samples', 'AFICv: test samples',\n",
    "]\n",
    "print(\"=== Data Dimensions Summary (W=30) ===\\n\")\n",
    "print(df[display_cols].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tensor Shapes (samples, W, features) ===\n",
      "\n",
      "Machine Corr: X_train shape Corr: X_test shape AFICv: X_train shape AFICv: X_test shape\n",
      "     M1     (17731, 30, 32)    (10196, 30, 32)      (17731, 30, 16)     (10196, 30, 16)\n",
      "     M2     (46219, 30, 24)    (26511, 30, 24)      (46219, 30, 17)     (26511, 30, 17)\n",
      "     M3     (21820, 30, 30)    (13696, 30, 30)      (21820, 30, 15)     (13696, 30, 15)\n",
      "     M4     (54028, 30, 24)    (34092, 30, 24)      (54028, 30, 17)     (34092, 30, 17)\n"
     ]
    }
   ],
   "source": [
    "# Full shapes table\n",
    "shape_cols = [\n",
    "    'Machine',\n",
    "    'Corr: X_train shape', 'Corr: X_test shape',\n",
    "    'AFICv: X_train shape', 'AFICv: X_test shape',\n",
    "]\n",
    "print(\"=== Tensor Shapes (samples, W, features) ===\\n\")\n",
    "print(df[shape_cols].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LaTeX Table ===\n",
      "\n",
      "\\begin{table}[htbp]\n",
      "    \\centering\n",
      "    \\caption{Data dimensions after preprocessing and sliding window ($W=30$).}\n",
      "    \\label{tab:data_dimensions}\n",
      "    \\resizebox{\\columnwidth}{!}{%\n",
      "    \\begin{tabular}{@{}l cc cc cc cc@{}}\n",
      "        \\toprule\n",
      "        & & & \\multicolumn{3}{c}{\\textbf{Correlation-based}} & \\multicolumn{3}{c}{\\textbf{AFICv Stratified (90\\%)}} \\\\\n",
      "        \\cmidrule(lr){4-6} \\cmidrule(lr){7-9}\n",
      "        \\textbf{Machine} & \\textbf{Train} & \\textbf{Test} & Features & Train & Test & Features & Train & Test \\\\\n",
      "        & units & units & & samples & samples & & samples & samples \\\\\n",
      "        \\midrule\n",
      "        M1 & 100 & 100 & 32 & 17731 & 10196 & 16 & 17731 & 10196 \\\n",
      "        M2 & 260 & 259 & 24 & 46219 & 26511 & 17 & 46219 & 26511 \\\n",
      "        M3 & 100 & 100 & 30 & 21820 & 13696 & 15 & 21820 & 13696 \\\n",
      "        M4 & 249 & 248 & 24 & 54028 & 34092 & 17 & 54028 & 34092 \\\n",
      "        \\bottomrule\n",
      "    \\end{tabular}%\n",
      "    }\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "# LaTeX table for thesis\n",
    "print(\"=== LaTeX Table ===\")\n",
    "print()\n",
    "print(r\"\\begin{table}[htbp]\")\n",
    "print(r\"    \\centering\")\n",
    "print(r\"    \\caption{Data dimensions after preprocessing and sliding window ($W=30$).}\")\n",
    "print(r\"    \\label{tab:data_dimensions}\")\n",
    "print(r\"    \\resizebox{\\columnwidth}{!}{%\")\n",
    "print(r\"    \\begin{tabular}{@{}l cc cc cc cc@{}}\")\n",
    "print(r\"        \\toprule\")\n",
    "print(r\"        & & & \\multicolumn{3}{c}{\\textbf{Correlation-based}} & \\multicolumn{3}{c}{\\textbf{AFICv Stratified (90\\%)}} \\\\\")\n",
    "print(r\"        \\cmidrule(lr){4-6} \\cmidrule(lr){7-9}\")\n",
    "print(r\"        \\textbf{Machine} & \\textbf{Train} & \\textbf{Test} & Features & Train & Test & Features & Train & Test \\\\\")\n",
    "print(r\"        & units & units & & samples & samples & & samples & samples \\\\\")\n",
    "print(r\"        \\midrule\")\n",
    "for _, r in df.iterrows():\n",
    "    print(f\"        {r['Machine']} & {r['Train units']} & {r['Test units']} & \"\n",
    "          f\"{r['Corr: features']} & {r['Corr: train samples']} & {r['Corr: test samples']} & \"\n",
    "          f\"{r['AFICv: features']} & {r['AFICv: train samples']} & {r['AFICv: test samples']} \\\\\")\n",
    "print(r\"        \\bottomrule\")\n",
    "print(r\"    \\end{tabular}%\")\n",
    "print(r\"    }\")\n",
    "print(r\"\\end{table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
