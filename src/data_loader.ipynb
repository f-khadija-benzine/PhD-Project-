{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed847630-f993-4b08-82aa-1dd569588e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FD001DataLoader:\n",
    "    \"\"\"\n",
    "    Data loader specifically for NASA C-MAPSS FD001 dataset\n",
    "    \n",
    "    Handles:\n",
    "    - Loading training/test data\n",
    "    - RUL calculation and loading\n",
    "    - Data validation\n",
    "    - Basic preprocessing options\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_path=\"data/raw_data/C_MAPSS\"):\n",
    "        self.data_path = Path(data_path)\n",
    "        self.columns = self._define_columns()\n",
    "        \n",
    "        # Cache for loaded data\n",
    "        self._train_data = None\n",
    "        self._test_data = None\n",
    "        self._rul_data = None\n",
    "        \n",
    "        print(f\"ğŸ—ï¸ FD001DataLoader initialized\")\n",
    "        print(f\"   Data path: {self.data_path}\")\n",
    "        print(f\"   Expected columns: {len(self.columns)}\")\n",
    "\n",
    "    def _define_columns(self):\n",
    "        \"\"\"Define column names for FD001 dataset\"\"\"\n",
    "        columns = ['engine_id', 'cycle', 'op_setting_1', 'op_setting_2', 'op_setting_3']\n",
    "        columns += [f'sensor_{i}' for i in range(1, 22)]  # 21 sensors\n",
    "        return columns\n",
    "        \n",
    "    def load_train_data(self, force_reload=False):\n",
    "        \"\"\"Load FD001 training data\"\"\"\n",
    "        if self._train_data is not None and not force_reload:\n",
    "            return self._train_data\n",
    "        \n",
    "        train_file = self.data_path / \"train_FD001.txt\"\n",
    "        \n",
    "        if not train_file.exists():\n",
    "            print(f\"âŒ Training file not found: {train_file}\")\n",
    "            print(\"ğŸ’¡ Using sample data for development...\")\n",
    "            return train_data  # Use the sample data created above\n",
    "        \n",
    "        try:\n",
    "            print(f\"ğŸ“‚ Loading training data from {train_file}...\")\n",
    "            self._train_data = pd.read_csv(train_file, sep=r'\\s+', header=None, names=self.columns)\n",
    "            \n",
    "            print(f\"âœ… Training data loaded successfully!\")\n",
    "            print(f\"   Shape: {self._train_data.shape}\")\n",
    "            print(f\"   Engines: {self._train_data['engine_id'].nunique()}\")\n",
    "            \n",
    "            # Calculate RUL for training data\n",
    "            self._train_data = self._calculate_rul_training(self._train_data)\n",
    "            \n",
    "            return self._train_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error loading training data: {e}\")\n",
    "            return None\n",
    "            \n",
    "    def load_test_data(self, force_reload=False):\n",
    "        \"\"\"Load FD001 test data\"\"\"\n",
    "        if self._test_data is not None and not force_reload:\n",
    "            return self._test_data\n",
    "        \n",
    "        test_file = self.data_path / \"test_FD001.txt\"\n",
    "        \n",
    "        if not test_file.exists():\n",
    "            print(f\"âŒ Test file not found: {test_file}\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            print(f\"ğŸ“‚ Loading test data from {test_file}...\")\n",
    "            self._test_data = pd.read_csv(test_file, sep=r'\\s+', header=None, names=self.columns)\n",
    "            \n",
    "            print(f\"âœ… Test data loaded successfully!\")\n",
    "            print(f\"   Shape: {self._test_data.shape}\")\n",
    "            print(f\"   Engines: {self._test_data['engine_id'].nunique()}\")\n",
    "            \n",
    "            return self._test_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error loading test data: {e}\")\n",
    "            return None\n",
    "\n",
    "    def load_rul_data(self, force_reload=False):\n",
    "        \"\"\"Load true RUL values for test data\"\"\"\n",
    "        if self._rul_data is not None and not force_reload:\n",
    "            return self._rul_data\n",
    "        \n",
    "        rul_file = self.data_path / \"RUL_FD001.txt\"\n",
    "        \n",
    "        if not rul_file.exists():\n",
    "            print(f\"âŒ RUL file not found: {rul_file}\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            print(f\"ğŸ“‚ Loading RUL data from {rul_file}...\")\n",
    "            self._rul_data = pd.read_csv(rul_file, header=None, names=['RUL'])\n",
    "            self._rul_data['engine_id'] = range(1, len(self._rul_data) + 1)\n",
    "            \n",
    "            print(f\"âœ… RUL data loaded successfully!\")\n",
    "            print(f\"   Shape: {self._rul_data.shape}\")\n",
    "            print(f\"   RUL range: {self._rul_data['RUL'].min()}-{self._rul_data['RUL'].max()}\")\n",
    "            \n",
    "            return self._rul_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error loading RUL data: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _calculate_rul_training(self, data):\n",
    "        \"\"\"Calculate RUL for training data (reverse cycle count)\"\"\"\n",
    "        print(\"ğŸ”¢ Calculating RUL for training data...\")\n",
    "        \n",
    "        data_with_rul = data.copy()\n",
    "        \n",
    "        # For each engine, calculate RUL as (max_cycle - current_cycle)\n",
    "        for engine_id in data['engine_id'].unique():\n",
    "            engine_mask = data_with_rul['engine_id'] == engine_id\n",
    "            max_cycle = data_with_rul[engine_mask]['cycle'].max()\n",
    "            data_with_rul.loc[engine_mask, 'RUL'] = max_cycle - data_with_rul.loc[engine_mask, 'cycle']\n",
    "        \n",
    "        print(f\"âœ… RUL calculated for training data\")\n",
    "        return data_with_rul\n",
    "\n",
    "    def validate_data(self, data, data_type=\"unknown\"):\n",
    "        \"\"\"Validate loaded data quality\"\"\"\n",
    "        print(f\"ğŸ” Validating {data_type} data...\")\n",
    "        \n",
    "        issues = []\n",
    "        \n",
    "        # Check basic structure\n",
    "        expected_cols = len(self.columns)\n",
    "        if 'RUL' in data.columns:\n",
    "            expected_cols += 1\n",
    "            \n",
    "        if data.shape[1] < expected_cols - 1:  # Allow some flexibility\n",
    "            issues.append(f\"Unexpected column count: {data.shape[1]} (expected ~{expected_cols})\")\n",
    "        \n",
    "        # Check for missing values\n",
    "        missing_count = data.isnull().sum().sum()\n",
    "        if missing_count > 0:\n",
    "            issues.append(f\"Found {missing_count} missing values\")\n",
    "        \n",
    "        # Check engine ID progression\n",
    "        for engine_id in data['engine_id'].unique()[:5]:  # Check first 5 engines\n",
    "            engine_data = data[data['engine_id'] == engine_id]\n",
    "            cycles = sorted(engine_data['cycle'].values)\n",
    "            expected_cycles = list(range(1, len(cycles) + 1))\n",
    "            if cycles != expected_cycles:\n",
    "                issues.append(f\"Engine {engine_id} has irregular cycle progression\")\n",
    "                break\n",
    "        \n",
    "        # Check sensor value ranges (basic sanity check)\n",
    "        sensor_cols = [col for col in data.columns if col.startswith('sensor_')]\n",
    "        for col in sensor_cols[:3]:  # Check first 3 sensors\n",
    "            if data[col].std() == 0:\n",
    "                issues.append(f\"{col} has zero variance (constant values)\")\n",
    "        \n",
    "        if len(issues) == 0:\n",
    "            print(f\"âœ… {data_type} data validation passed!\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ {data_type} data validation found {len(issues)} issues:\")\n",
    "            for issue in issues:\n",
    "                print(f\"   - {issue}\")\n",
    "        \n",
    "        return len(issues) == 0\n",
    "\n",
    "    def get_data_summary(self):\n",
    "        \"\"\"Get comprehensive data summary\"\"\"\n",
    "        print(\"ğŸ“Š FD001 Dataset Summary\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        train_data = self.load_train_data()\n",
    "        test_data = self.load_test_data()\n",
    "        rul_data = self.load_rul_data()\n",
    "        \n",
    "        if train_data is not None:\n",
    "            print(f\"ğŸ“ˆ Training Data:\")\n",
    "            print(f\"   Shape: {train_data.shape}\")\n",
    "            print(f\"   Engines: {train_data['engine_id'].nunique()}\")\n",
    "            print(f\"   Total cycles: {train_data.shape[0]:,}\")\n",
    "            if 'RUL' in train_data.columns:\n",
    "                print(f\"   RUL range: {train_data['RUL'].min()}-{train_data['RUL'].max()}\")\n",
    "        \n",
    "        if test_data is not None:\n",
    "            print(f\"ğŸ“Š Test Data:\")\n",
    "            print(f\"   Shape: {test_data.shape}\")\n",
    "            print(f\"   Engines: {test_data['engine_id'].nunique()}\")\n",
    "            print(f\"   Total cycles: {test_data.shape[0]:,}\")\n",
    "        \n",
    "        if rul_data is not None:\n",
    "            print(f\"ğŸ¯ RUL Data:\")\n",
    "            print(f\"   Shape: {rul_data.shape}\")\n",
    "            print(f\"   RUL range: {rul_data['RUL'].min()}-{rul_data['RUL'].max()}\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd-pdm]",
   "language": "python",
   "name": "conda-env-phd-pdm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
